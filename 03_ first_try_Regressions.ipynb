{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Categorical, Integer\n",
    "\n",
    "# Model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import  accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_tweets</th>\n",
       "      <th>tweets</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>ID</th>\n",
       "      <th>E/I</th>\n",
       "      <th>S/N</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>m</td>\n",
       "      <td>742</td>\n",
       "      <td>back on the way up  now at the</td>\n",
       "      <td>8447</td>\n",
       "      <td>16622</td>\n",
       "      <td>21559</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>m</td>\n",
       "      <td>742</td>\n",
       "      <td>guatnimnwkget your copy now</td>\n",
       "      <td>8447</td>\n",
       "      <td>16622</td>\n",
       "      <td>21559</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>m</td>\n",
       "      <td>742</td>\n",
       "      <td>Ex8Dz0RxCP  thanks for the follow   enjoy you...</td>\n",
       "      <td>8447</td>\n",
       "      <td>16622</td>\n",
       "      <td>21559</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>m</td>\n",
       "      <td>742</td>\n",
       "      <td>rmbxwmyc 9n   axel doorman  in the back  dten...</td>\n",
       "      <td>8447</td>\n",
       "      <td>16622</td>\n",
       "      <td>21559</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>m</td>\n",
       "      <td>742</td>\n",
       "      <td>1tfzadklqt     xxx d  all i wanted to say to ...</td>\n",
       "      <td>8447</td>\n",
       "      <td>16622</td>\n",
       "      <td>21559</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271987</th>\n",
       "      <td>354</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>f</td>\n",
       "      <td>648</td>\n",
       "      <td>5wvi8zgwm4 en agosto voy a estar en  empodera...</td>\n",
       "      <td>660</td>\n",
       "      <td>1125</td>\n",
       "      <td>782</td>\n",
       "      <td>26</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271988</th>\n",
       "      <td>355</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>f</td>\n",
       "      <td>648</td>\n",
       "      <td>idjpjhhjzv me quise hacer  la artista  a las ...</td>\n",
       "      <td>660</td>\n",
       "      <td>1125</td>\n",
       "      <td>782</td>\n",
       "      <td>26</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271989</th>\n",
       "      <td>356</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>f</td>\n",
       "      <td>648</td>\n",
       "      <td>uh0j41uuqv  mejorate   D mi socio me di 5 aos...</td>\n",
       "      <td>660</td>\n",
       "      <td>1125</td>\n",
       "      <td>782</td>\n",
       "      <td>26</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271990</th>\n",
       "      <td>357</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>f</td>\n",
       "      <td>648</td>\n",
       "      <td>anspqtq 07i cada vez ms  o  acuden al  para l...</td>\n",
       "      <td>660</td>\n",
       "      <td>1125</td>\n",
       "      <td>782</td>\n",
       "      <td>26</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271991</th>\n",
       "      <td>358</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>f</td>\n",
       "      <td>648</td>\n",
       "      <td>2pywrxwflt\\r</td>\n",
       "      <td>660</td>\n",
       "      <td>1125</td>\n",
       "      <td>782</td>\n",
       "      <td>26</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271992 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  type gender  num_tweets  \\\n",
       "0                0  ENFJ      m         742   \n",
       "1                1  ENFJ      m         742   \n",
       "2                2  ENFJ      m         742   \n",
       "3                3  ENFJ      m         742   \n",
       "4                4  ENFJ      m         742   \n",
       "...            ...   ...    ...         ...   \n",
       "271987         354  ISTP      f         648   \n",
       "271988         355  ISTP      f         648   \n",
       "271989         356  ISTP      f         648   \n",
       "271990         357  ISTP      f         648   \n",
       "271991         358  ISTP      f         648   \n",
       "\n",
       "                                                   tweets  followers_count  \\\n",
       "0                     back on the way up  now at the                  8447   \n",
       "1                        guatnimnwkget your copy now                  8447   \n",
       "2        Ex8Dz0RxCP  thanks for the follow   enjoy you...             8447   \n",
       "3        rmbxwmyc 9n   axel doorman  in the back  dten...             8447   \n",
       "4        1tfzadklqt     xxx d  all i wanted to say to ...             8447   \n",
       "...                                                   ...              ...   \n",
       "271987   5wvi8zgwm4 en agosto voy a estar en  empodera...              660   \n",
       "271988   idjpjhhjzv me quise hacer  la artista  a las ...              660   \n",
       "271989   uh0j41uuqv  mejorate   D mi socio me di 5 aos...              660   \n",
       "271990   anspqtq 07i cada vez ms  o  acuden al  para l...              660   \n",
       "271991                                       2pywrxwflt\\r              660   \n",
       "\n",
       "        statuses_count  favorites_count  listed_count      ID E/I S/N T/F J/P  \n",
       "0                16622            21559           121     0.0   E   N   F   J  \n",
       "1                16622            21559           121     0.0   E   N   F   J  \n",
       "2                16622            21559           121     0.0   E   N   F   J  \n",
       "3                16622            21559           121     0.0   E   N   F   J  \n",
       "4                16622            21559           121     0.0   E   N   F   J  \n",
       "...                ...              ...           ...     ...  ..  ..  ..  ..  \n",
       "271987            1125              782            26  1069.0   I   S   T   P  \n",
       "271988            1125              782            26  1069.0   I   S   T   P  \n",
       "271989            1125              782            26  1069.0   I   S   T   P  \n",
       "271990            1125              782            26  1069.0   I   S   T   P  \n",
       "271991            1125              782            26  1069.0   I   S   T   P  \n",
       "\n",
       "[271992 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mbti_twitter.csv', sep=\"\\t\", lineterminator='\\n')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "271987    15\n",
       "271988    15\n",
       "271989    15\n",
       "271990    15\n",
       "271991    15\n",
       "Name: type of encoding, Length: 271992, dtype: int32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "data['type of encoding'] = enc.fit_transform(data['type'])\n",
    "target = data['type of encoding'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271992, 525229)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer() \n",
    "train =  vect.fit_transform(data[\"tweets\"].astype(str))\n",
    "train.shape\n",
    "# (150470, 378898)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217593, 525229) (217593,) (54399, 525229) (54399,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.2, stratify=target, random_state=42)\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))\n",
    "#(217593, 525229) (217593,) (54399, 525229) (54399,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparam_grid_rf = {\\n    'n_estimators': Integer(100, 200),                    \\n    'max_features': Categorical(['sqrt', 'log2', None])                           \\n}\\nmodel=RandomForestClassifier(random_state=42, n_jobs=-1)\\nRandFor_grid = BayesSearchCV(model, param_grid_rf, scoring='accuracy', verbose=1, cv=2)\\nRandFor_grid.fit(X_train, y_train)\\nprint(RandFor_grid.best_estimator_)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lÃ¤uft zu lange: 4311min\n",
    "param_grid_rf = {\n",
    "    'n_estimators': Integer(100, 200),                    \n",
    "    'max_features': Categorical(['sqrt', 'log2', None])                           \n",
    "}\n",
    "model=RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "RandFor_grid = BayesSearchCV(model, param_grid_rf, scoring='accuracy', verbose=1, cv=2)\n",
    "RandFor_grid.fit(X_train, y_train)\n",
    "print(RandFor_grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparam_grid_lr = {                      \\n    'solver': Categorical(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),  \\n    'max_iter': Integer(100,200)                                   \\n}\\nmodel=LogisticRegression(random_state=42, n_jobs=-1)\\nlogModel_grid = BayesSearchCV(model, param_grid_lr,scoring='accuracy', verbose=1, cv=2)\\nlogModel_grid.fit(X_train, y_train)\\n\\n#LogisticRegression(class_weight='balanced', max_iter=500, random_state=42, solver='liblinear')\\nprint(logModel_grid.best_estimator_)\\n#LogisticRegression(max_iter=181, n_jobs=-1, random_state=42, solver='liblinear')\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid_lr = {                      \n",
    "    'solver': Categorical(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),  \n",
    "    'max_iter': Integer(100,200)                                   \n",
    "}\n",
    "model=LogisticRegression(random_state=42, n_jobs=-1)\n",
    "logModel_grid = BayesSearchCV(model, param_grid_lr,scoring='accuracy', verbose=1, cv=2)\n",
    "logModel_grid.fit(X_train, y_train)\n",
    "\n",
    "#LogisticRegression(class_weight='balanced', max_iter=500, random_state=42, solver='liblinear')\n",
    "print(logModel_grid.best_estimator_)\n",
    "#LogisticRegression(max_iter=181, n_jobs=-1, random_state=42, solver='liblinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Random Forest\\nrandom_forest = RandomForestClassifier(n_estimators=200, random_state = 42).fit(X_train, y_train)\\n\\n# make predictions for test data\\nY_pred = random_forest.predict(X_test)\\npredictions = [round(value) for value in Y_pred]\\n\\n# evaluate predictions\\naccuracy = accuracy_score(y_test, predictions)\\naccuracies[\\'Random Forest\\'] = accuracy* 100.0 \\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\\n\\nfrom sklearn.metrics import classification_report\\nprint(classification_report(y_test, predictions))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In random forests (see RandomForestClassifier and RandomForestRegressor classes), \n",
    "#each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set.\n",
    "#Furthermore, when splitting each node during the construction of a tree, the best split is found through an exhaustive search of the features values of either all input features or a random subset of size max_features. \n",
    "#The purpose of these two sources of randomness is to decrease the variance of the forest estimator. \n",
    "\n",
    "#Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=200, random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracies['Random Forest'] = accuracy* 100.0 \n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# 26,56 n_estimators=100, random_state = 1\n",
    "# 27.66% n_estimators=200, random_state = 42, bootstrap=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\svcsc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1216: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy: 32.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.43      0.37      8478\n",
      "           1       0.34      0.32      0.33      5483\n",
      "           2       0.36      0.34      0.35      6001\n",
      "           3       0.35      0.34      0.35      2780\n",
      "           4       0.29      0.36      0.32       955\n",
      "           5       0.26      0.33      0.29       888\n",
      "           6       0.31      0.36      0.33      1566\n",
      "           7       0.19      0.26      0.22       363\n",
      "           8       0.35      0.31      0.33      6126\n",
      "           9       0.31      0.24      0.27      4227\n",
      "          10       0.41      0.31      0.35      8057\n",
      "          11       0.27      0.27      0.27      3821\n",
      "          12       0.21      0.26      0.23      1853\n",
      "          13       0.22      0.24      0.23       507\n",
      "          14       0.26      0.25      0.25      2588\n",
      "          15       0.24      0.36      0.29       706\n",
      "\n",
      "    accuracy                           0.32     54399\n",
      "   macro avg       0.29      0.31      0.30     54399\n",
      "weighted avg       0.33      0.32      0.32     54399\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\svcsc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=181, n_jobs=6, random_state=42, solver='liblinear', verbose=1).fit(X_train, y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracies['Logistic Regression'] = accuracy* 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Accuracy: 33.71% class_weight='balanced', max_iter=500, random_state=42, solver='liblinear'\n",
    "# Accuracy: 34.05% max_iter=181, n_jobs=-1, random_state=42, solver='liblinear', verbose=1\n",
    "# Accuracy: 32.33% class_weight='balanced', max_iter=181, n_jobs=-1, random_state=42, solver='liblinear', verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           2.4491         3865.38m\n",
      "         2           2.4416         3823.61m\n",
      "         3           2.4370         3793.61m\n",
      "         4           2.4325         3759.28m\n",
      "         5           2.4287         3722.98m\n",
      "         6           2.4255         3674.26m\n",
      "         7           2.4221         3624.44m\n",
      "         8           2.4184         3580.28m\n",
      "         9           2.4160         3539.27m\n",
      "        10           2.4135         3498.66m\n",
      "        20           2.3934         3094.19m\n",
      "        30           2.3789         2725.47m\n",
      "        40           2.3667         2347.77m\n",
      "        50           2.3574         1953.50m\n",
      "        60           2.3483         1561.18m\n",
      "        70           2.3409         1170.49m\n",
      "        80           2.3340          779.99m\n",
      "        90           2.3274          389.86m\n",
      "       100           2.3209            0.00s\n",
      "Accuracy: 22.72%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.94      0.30      8478\n",
      "           1       0.70      0.07      0.13      5483\n",
      "           2       0.44      0.10      0.16      6001\n",
      "           3       0.64      0.11      0.18      2780\n",
      "           4       0.77      0.17      0.28       955\n",
      "           5       0.64      0.12      0.20       888\n",
      "           6       0.77      0.12      0.20      1566\n",
      "           7       0.64      0.17      0.27       363\n",
      "           8       0.39      0.12      0.18      6126\n",
      "           9       0.56      0.06      0.11      4227\n",
      "          10       0.36      0.14      0.20      8057\n",
      "          11       0.80      0.06      0.11      3821\n",
      "          12       0.64      0.04      0.08      1853\n",
      "          13       0.69      0.11      0.20       507\n",
      "          14       0.87      0.05      0.09      2588\n",
      "          15       0.73      0.09      0.15       706\n",
      "\n",
      "    accuracy                           0.23     54399\n",
      "   macro avg       0.61      0.15      0.18     54399\n",
      "weighted avg       0.51      0.23      0.18     54399\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#This algorithm builds an additive model in a forward stage-wise fashion; \n",
    "#it allows for the optimization of arbitrary differentiable loss functions. \n",
    "#In each stage n_classes_ regression trees are fit on the negative gradient of the loss function\n",
    "#GradientBoostingClassifier supports both binary and multi-class classification.\n",
    "\n",
    "gradientboost = GradientBoostingClassifier(random_state = 42, max_depth=1, verbose= 1).fit(X_train, y_train)\n",
    "\n",
    "Y_pred = gradientboost.predict(X_test)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracies['Logistic Regression'] = accuracy* 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
